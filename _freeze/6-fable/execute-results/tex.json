{
  "hash": "8d6614698efcd4e9a1248e7e86fc4c3e",
  "result": {
    "markdown": "---\ntitle: \"Time Series Analysis & Forecasting Using R\"\nsubtitle: \"6. Introduction to forecasting\"\n---\n\n\n## Outline\n\n\\vspace*{0.7cm}\\tableofcontents\n\n\n\n\n\n\n# Statistical forecasting\n\n## Forecasting is difficult\n\n\\full{hopecasts2}\n\n## What can we forecast?\n\n\\full{nasdaq-stock-market}\n\n## What can we forecast?\n\n\\full{Forex2}\n\n## What can we forecast?\n\n\\full{pills}\n\n## What can we forecast?\n\n\\full{elecwires2}\n\n## What can we forecast?\n\n\\full{AusBOM}\n\n## What can we forecast?\n\n\\full{ts22015}\n\n## What can we forecast?\n\n\\full{comet}\n\n## Which is easiest to forecast?\n\n 1. daily electricity demand in 3 days time\n 2. timing of next Halley's comet appearance\n 3. time of sunrise this day next year\n 4. Google stock price tomorrow\n 5. Google stock price in 6 months time\n 6. maximum temperature tomorrow\n 7. exchange rate of \\$US/AUS next week\n 8. total sales of drugs in Australian pharmacies next month\n\n\\pause\n\n - how do we measure \"easiest\"?\n - what makes something easy/difficult to forecast?\n\n## Factors affecting forecastability\n\nSomething is easier to forecast if:\n\n - we have a good understanding of the factors that contribute to it\n - there is lots of data available;\n - the forecasts cannot affect the thing we are trying to forecast.\n - there is relatively low natural/unexplainable random variation.\n - the future is somewhat similar to the past\n\n## Random futures\n\n\n::: {.cell hash='6-fable_cache/beamer/austa_6c9e745abb766e39c6323be192106998'}\n\n:::\n\n\n\\forecast\\pause\n\n\n::: {.cell hash='6-fable_cache/beamer/austa1_d41e40af9dc6b60ddc9400a070dfee8f'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa1-1.pdf)\n:::\n:::\n\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa2_d1f5932bff47126a08e8744633fe6c71'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa2-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa3_100eddafb0ce0ec07fd0d96ee40da760'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa3-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa4_614d4eda97ac225589edcf3720594795'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa4-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa5_79dcad51138b01b9e8149b6e469a6248'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa5-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa6_cefb0dbcb272fe46915eb4bf19021a6e'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa6-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa7_e06d741ea2b1cbc8317c146cd23e8514'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa7-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa8_2e86b7d009f35e82421084e3303163f3'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa8-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa9_e008e0a8cfcd7aa91d406f376062b99d'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa9-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n## Random futures\n\n\\forecast\n\n\n::: {.cell hash='6-fable_cache/beamer/austa9b_cb4a6680ed13a36748ec04e94c291d24'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/austa9b-1.pdf)\n:::\n:::\n\n\n\\simfutures\n\n\\only<2>{\\begin{textblock}{8.5}(.3,6.5)\\begin{alertblock}{}\\fontsize{13}{15}\\sf\n``He who sees the past as surprise-free is bound to have a future full of surprises.''\\\\\\mbox{}\\hfill{\\small (Amos Tversky)}\n\\end{alertblock}\\end{textblock}\n}\n\n## Statistical forecasting\n\n- Thing to be forecast: $y_{T+h}$.\n- What we know: $y_1,\\dots,y_T$.\n- Forecast distribution: ${y}_{T+h|t} = y_{T+h} \\mid \\{y_1,y_2,\\dots,y_{T}\\}$.\n- Point forecast: $\\hat{y}_{T+h|T} =\\text{E}[y_{T+h} \\mid y_1,\\dots,y_T]$.\n- Forecast variance: $\\text{Var}[y_{t}  \\mid y_1,\\dots,y_T]$\n- Prediction interval is a range of values of $y_{T+h}$ with high probability.\n\n# Benchmark methods\n\n## Some simple forecasting methods\n\n\n::: {.cell hash='6-fable_cache/beamer/ausbeer_974baa8074fb8b7239ca42a5c43a5d66'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/ausbeer-1.pdf)\n:::\n:::\n\n\n\\begin{textblock}{7}(0.4,7.9)\n\\begin{alertblock}{}\n\\small{How would you forecast these series?}\n\\end{alertblock}\n\\end{textblock}\n\n## Some simple forecasting methods\n\n\n::: {.cell hash='6-fable_cache/beamer/pigs_fa0b3583fb392cb0d52a039472ab7e72'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/pigs-1.pdf)\n:::\n:::\n\n\n\\begin{textblock}{7}(0.4,7.9)\n\\begin{alertblock}{}\n\\small{How would you forecast these series?}\n\\end{alertblock}\n\\end{textblock}\n\n## Some simple forecasting methods\n\n\n::: {.cell hash='6-fable_cache/beamer/dj_257ccc32390944e37693e2073c13eb0d'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj-1.pdf)\n:::\n:::\n\n\n\\begin{textblock}{7}(0.4,7.9)\n\\begin{alertblock}{}\n\\small{How would you forecast these series?}\n\\end{alertblock}\n\\end{textblock}\n\n## Some simple forecasting methods\n\\fontsize{13}{14}\\sf\n\n### `MEAN(y)`: Average method\n\n  * Forecast of all future values is equal to mean of historical data $\\{y_1,\\dots,y_T\\}$.\n  * Forecasts: $\\hat{y}_{T+h|T} = \\bar{y} = (y_1+\\dots+y_T)/T$\n\n\n::: {.cell hash='6-fable_cache/beamer/mean-method-explained_55901164c0739446a6d8d706e61aa3e5'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/mean-method-explained-1.pdf)\n:::\n:::\n\n\n## Some simple forecasting methods\n\\fontsize{13}{14}\\sf\n\n### `NAIVE(y)`: Naïve method\n\n  * Forecasts equal to last observed value.\n  * Forecasts: $\\hat{y}_{T+h|T} =y_T$.\n  * Consequence of efficient market hypothesis.\n\n\n::: {.cell hash='6-fable_cache/beamer/naive-method-explained_e732f4facb13351313183a55e2f5a63d'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/naive-method-explained-1.pdf)\n:::\n:::\n\n\n## Some simple forecasting methods\n\\fontsize{13}{14}\\sf\n\n### `SNAIVE(y ~ lag(m))`: Seasonal naïve method\n\n  * Forecasts equal to last value from same season.\n  * Forecasts: $\\hat{y}_{T+h|T} =y_{T+h-m(k+1)}$, where $m=$ seasonal period and $k$ is the integer part of $(h-1)/m$.\n\n\n::: {.cell hash='6-fable_cache/beamer/snaive-method-explained_33e8856af21b0acd3ae38f13e8573c80'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/snaive-method-explained-1.pdf)\n:::\n:::\n\n\n## Some simple forecasting methods\n\\fontsize{13}{14}\\sf\n\n### `RW(y ~ drift())`: Drift method\n\n * Forecasts equal to last value plus average change.\n * Forecasts:\\vspace*{-.7cm}\n\n \\begin{align*}\n \\hat{y}_{T+h|T} & =  y_{T} + \\frac{h}{T-1}\\sum_{t=2}^T (y_t-y_{t-1})\\\\\n                 & = y_T + \\frac{h}{T-1}(y_T -y_1).\n \\end{align*}\\vspace*{-0.2cm}\n\n   * Equivalent to extrapolating a line drawn between first and last observations.\n\n## Some simple forecasting methods\n\n### Drift method\n\n\n::: {.cell hash='6-fable_cache/beamer/drift-method-explained_fdd9583984cc2ffc90b86db3d00f041e'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/drift-method-explained-1.pdf)\n:::\n:::\n\n\n## Model fitting\n\nThe `model()` function trains models to data.\n\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/brick-model_34eb59eed2c519eb56eac82b514854bc'}\n\n```{.r .cell-code}\nbrick_fit <- aus_production |>\n  filter(!is.na(Bricks)) |>\n  model(\n    `Seasonal_naïve` = SNAIVE(Bricks),\n    `Naïve` = NAIVE(Bricks),\n    Drift = RW(Bricks ~ drift()),\n    Mean = MEAN(Bricks)\n  )\n```\n:::\n\n::: {.cell hash='6-fable_cache/beamer/brick-model2_e9b1ca25a558859b25599c72acac0188'}\n::: {.cell-output .cell-output-stdout}\n```\n# A mable: 1 x 4\n  Seasonal_naïve   Naïve         Drift    Mean\n         <model> <model>       <model> <model>\n1       <SNAIVE> <NAIVE> <RW w/ drift>  <MEAN>\n```\n:::\n:::\n\n\n\\vspace*{0.2cm}\\begin{alertblock}{}\nA \\texttt{mable} is a model table, each cell corresponds to a fitted model.\n\\end{alertblock}\n\n## Producing forecasts\n\n\\fontsize{10}{13}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/brick-fc_9fbad4000f53a05e0ddeb18d1082483c'}\n\n```{.r .cell-code}\nbrick_fc <- brick_fit |>\n  forecast(h = \"5 years\")\n```\n:::\n\n::: {.cell hash='6-fable_cache/beamer/brick-fbl_5f2be4117e0e175dad8f374c260390d5'}\n::: {.cell-output .cell-output-stdout}\n```\n# A fable: 80 x 4 [1Q]\n# Key:     .model [4]\n  .model         Quarter       Bricks .mean\n  <chr>            <qtr>       <dist> <dbl>\n1 Seasonal_naïve 2005 Q3 N(428, 2336)   428\n2 Seasonal_naïve 2005 Q4 N(397, 2336)   397\n3 Seasonal_naïve 2006 Q1 N(355, 2336)   355\n4 Seasonal_naïve 2006 Q2 N(435, 2336)   435\n# i 76 more rows\n```\n:::\n:::\n\n\n\\vspace*{0.2cm}\\begin{alertblock}{}\nA \\texttt{fable} is a forecast table with point forecasts and distributions.\n\\end{alertblock}\n\n## Visualising forecasts\n\n\\footnotesize\n\n\n::: {.cell hash='6-fable_cache/beamer/brick-fc-plot_a188077a9cc3ef24033f1e1c5725a743'}\n\n```{.r .cell-code}\nbrick_fc |>\n  autoplot(aus_production, level = NULL) +\n  labs(title = \"Forecasts for quarterly clay brick production\",\n       x = \"Year\", y = \"Millions of bricks\") +\n  guides(colour = guide_legend(title = \"Forecast\"))\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/brick-fc-plot-1.pdf)\n:::\n:::\n\n\n## Prediction intervals\n\\fontsize{10}{12}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/brick-fc-interval_e833b65b27311ab69460f6d24dc321ac'}\n\n```{.r .cell-code}\nbrick_fc |>\n  hilo(level = c(50, 75))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 80 x 6 [1Q]\n# Key:       .model [4]\n   .model         Quarter       Bricks .mean        `50%`        `75%`\n   <chr>            <qtr>       <dist> <dbl>       <hilo>       <hilo>\n 1 Seasonal_naïve 2005 Q3 N(428, 2336)   428 [395, 461]50 [372, 484]75\n 2 Seasonal_naïve 2005 Q4 N(397, 2336)   397 [364, 430]50 [341, 453]75\n 3 Seasonal_naïve 2006 Q1 N(355, 2336)   355 [322, 388]50 [299, 411]75\n 4 Seasonal_naïve 2006 Q2 N(435, 2336)   435 [402, 468]50 [379, 491]75\n 5 Seasonal_naïve 2006 Q3 N(428, 4672)   428 [382, 474]50 [349, 507]75\n 6 Seasonal_naïve 2006 Q4 N(397, 4672)   397 [351, 443]50 [318, 476]75\n 7 Seasonal_naïve 2007 Q1 N(355, 4672)   355 [309, 401]50 [276, 434]75\n 8 Seasonal_naïve 2007 Q2 N(435, 4672)   435 [389, 481]50 [356, 514]75\n 9 Seasonal_naïve 2007 Q3 N(428, 7008)   428 [372, 484]50 [332, 524]75\n10 Seasonal_naïve 2007 Q4 N(397, 7008)   397 [341, 453]50 [301, 493]75\n# i 70 more rows\n```\n:::\n:::\n\n\n## Prediction intervals\n\\fontsize{10}{12}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/brick-fc-interval2_83a74cd32f74c7f9a3288bea113061f4'}\n\n```{.r .cell-code}\nbrick_fc |>\n  hilo(level = c(50, 75)) |>\n  mutate(lower = `50%`$lower, upper = `50%`$upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 80 x 8 [1Q]\n# Key:       .model [4]\n   .model         Quarter       Bricks .mean        `50%`        `75%` lower upper\n   <chr>            <qtr>       <dist> <dbl>       <hilo>       <hilo> <dbl> <dbl>\n 1 Seasonal_naïve 2005 Q3 N(428, 2336)   428 [395, 461]50 [372, 484]75  395.  461.\n 2 Seasonal_naïve 2005 Q4 N(397, 2336)   397 [364, 430]50 [341, 453]75  364.  430.\n 3 Seasonal_naïve 2006 Q1 N(355, 2336)   355 [322, 388]50 [299, 411]75  322.  388.\n 4 Seasonal_naïve 2006 Q2 N(435, 2336)   435 [402, 468]50 [379, 491]75  402.  468.\n 5 Seasonal_naïve 2006 Q3 N(428, 4672)   428 [382, 474]50 [349, 507]75  382.  474.\n 6 Seasonal_naïve 2006 Q4 N(397, 4672)   397 [351, 443]50 [318, 476]75  351.  443.\n 7 Seasonal_naïve 2007 Q1 N(355, 4672)   355 [309, 401]50 [276, 434]75  309.  401.\n 8 Seasonal_naïve 2007 Q2 N(435, 4672)   435 [389, 481]50 [356, 514]75  389.  481.\n 9 Seasonal_naïve 2007 Q3 N(428, 7008)   428 [372, 484]50 [332, 524]75  372.  484.\n10 Seasonal_naïve 2007 Q4 N(397, 7008)   397 [341, 453]50 [301, 493]75  341.  453.\n# i 70 more rows\n```\n:::\n:::\n\n\n# Lab Session 11\n## Lab Session 11\n\n * Produce forecasts using an appropriate benchmark method for household wealth (`hh_budget`). Plot the results using `autoplot()`.\n * Produce forecasts using an appropriate benchmark method for Australian takeaway food turnover (`aus_retail`). Plot the results using `autoplot()`.\n\n# Residual diagnostics\n\n## Fitted values\n\n - $\\hat{y}_{t|t-1}$ is the forecast of $y_t$ based on observations $y_1,\\dots,y_t$.\n - We call these \"fitted values\".\n - Sometimes drop the subscript: $\\hat{y}_t \\equiv \\hat{y}_{t|t-1}$.\n - Often not true forecasts since parameters are estimated on all data.\n\n### For example:\n\n - $\\hat{y}_{t} = \\bar{y}$ for average method.\n - $\\hat{y}_{t} = y_{t-1} + (y_{T}-y_1)/(T-1)$ for drift method.\n\n## Forecasting residuals\n\n\\begin{block}{}\n\\textbf{Residuals in forecasting:} difference between observed value and its fitted value: $e_t = y_t-\\hat{y}_{t|t-1}$.\n\\end{block}\n\\pause\\fontsize{13}{15}\\sf\n\n\\alert{Assumptions}\n\n  1. $\\{e_t\\}$ uncorrelated. If they aren't, then information left in  residuals that should be used in computing forecasts.\n  2. $\\{e_t\\}$ have mean zero. If they don't, then forecasts are biased.\n\n\\pause\n\n\\alert{Useful properties} (for prediction intervals)\n\n  3. $\\{e_t\\}$ have constant variance.\n  4. $\\{e_t\\}$ are normally distributed.\n\n## Facebook closing stock price\n\\fontsize{9}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/fbf_df8e1b7a5166e050f3c29cbc4ba9a7cb'}\n\n```{.r .cell-code}\nfb_stock <- gafa_stock |>\n  filter(Symbol == \"FB\")\nfb_stock |> autoplot(Close)\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/fbf-1.pdf)\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/augment_b5cb0c35abc3db94d6e291c2be4b9aed'}\n\n```{.r .cell-code}\nfb_stock <- fb_stock |>\n  mutate(trading_day = row_number()) |>\n  update_tsibble(index = trading_day, regular = TRUE)\nfit <- fb_stock |> model(NAIVE(Close))\naugment(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 1,258 x 7 [1]\n# Key:       Symbol, .model [1]\n   Symbol .model       trading_day Close .fitted .resid .innov\n   <chr>  <chr>              <int> <dbl>   <dbl>  <dbl>  <dbl>\n 1 FB     NAIVE(Close)           1  54.7    NA   NA     NA    \n 2 FB     NAIVE(Close)           2  54.6    54.7 -0.150 -0.150\n 3 FB     NAIVE(Close)           3  57.2    54.6  2.64   2.64 \n 4 FB     NAIVE(Close)           4  57.9    57.2  0.720  0.720\n 5 FB     NAIVE(Close)           5  58.2    57.9  0.310  0.310\n 6 FB     NAIVE(Close)           6  57.2    58.2 -1.01  -1.01 \n 7 FB     NAIVE(Close)           7  57.9    57.2  0.720  0.720\n 8 FB     NAIVE(Close)           8  55.9    57.9 -2.03  -2.03 \n 9 FB     NAIVE(Close)           9  57.7    55.9  1.83   1.83 \n10 FB     NAIVE(Close)          10  57.6    57.7 -0.140 -0.140\n# i 1,248 more rows\n```\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj4_686c45477ffe2c5f815d5543cad0cf79'}\n\n```{.r .cell-code}\naugment(fit) |>\n  ggplot(aes(x = trading_day)) +\n  geom_line(aes(y = Close, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\"))\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj4-1.pdf)\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj4a_b30a2d2f956a813a77d09c2cd0433ab4'}\n\n```{.r .cell-code}\naugment(fit) |>\n  filter(trading_day > 1100) |>\n  ggplot(aes(x = trading_day)) +\n  geom_line(aes(y = Close, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\"))\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj4a-1.pdf)\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj5_a8f465b96e2f3f4a0e652ccc0160fc8d'}\n\n```{.r .cell-code}\naugment(fit) |>\n  autoplot(.resid) +\n  labs(x = \"Day\", y = \"\", title = \"Residuals from naïve method\")\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj5-1.pdf)\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{11}{11}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj6_03d2d720eb42659664a1372af1a17e87'}\n\n```{.r .cell-code}\naugment(fit) |>\n  ggplot(aes(x = .resid)) +\n  geom_histogram(bins = 150) +\n  labs(title = \"Histogram of residuals\")\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj6-1.pdf)\n:::\n:::\n\n\n## Facebook closing stock price\n\\fontsize{11}{11}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj7_1c78279b1359c54220009c626883224c'}\n\n```{.r .cell-code}\naugment(fit) |>\n  ACF(.resid) |>\n  autoplot() + labs(title = \"ACF of residuals\")\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj7-1.pdf)\n:::\n:::\n\n\n## ACF of residuals\n\n  * We assume that the residuals are white noise (uncorrelated, mean zero, constant variance). If they aren't, then there is information left in  the residuals that should be used in computing forecasts.\n\n  * So a standard residual diagnostic is to check the ACF of the residuals of a forecasting method.\n\n  * We *expect* these to look like white noise.\n\n## Combined diagnostic graph\n\\fontsize{11}{11}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj8_4c0ca14b68d3e47c82e111324f2f3647'}\n\n```{.r .cell-code}\nfit |> gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj8-1.pdf)\n:::\n:::\n\n\n## Ljung-Box test\n\\fontsize{12}{13}\\sf\n\nTest whether *whole set* of $r_{k}$ values is significantly different from zero set.\n\n\\begin{block}{}\n\\centerline{$\\displaystyle\n Q = T(T+2) \\sum_{k=1}^\\ell (T-k)^{-1}r_k^2$\\qquad\nwhere $\\ell=$ max lag and $T=$ \\# observations}\n\\end{block}\n\n  * If each $r_k$ close to zero, $Q$ will be **small**.\n  * If some $r_k$ values large ($+$ or $-$), $Q$ will be **large**.\n  * My preferences: $h=10$ for non-seasonal data, $h=2m$ for seasonal data.\n  * If data are WN and $T$ large, $Q \\sim \\chi^2$ with $\\ell$ degrees of freedom.\n\n## Ljung-Box test\n\\fontsize{12}{13}\\sf\n\n\\begin{block}{}\n\\centerline{$\\displaystyle\n Q = T(T+2) \\sum_{k=1}^\\ell (T-k)^{-1}r_k^2$\\qquad\nwhere $\\ell=$ max lag and $T=$ \\# observations.}\n\\end{block}\n\n\\fontsize{11}{11}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/dj9extra_803ba83c5dc75c5c00e4b891222670cd'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/dj9extra-1.pdf)\n:::\n:::\n\n\n\\vspace*{-0.3cm}\n\n\n::: {.cell hash='6-fable_cache/beamer/dj9_e314443b60a153c757e7e68e8a92daab'}\n\n```{.r .cell-code}\n# lag = h\naugment(fit) |> features(.resid, ljung_box, lag = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  Symbol .model       lb_stat lb_pvalue\n  <chr>  <chr>          <dbl>     <dbl>\n1 FB     NAIVE(Close)    12.1     0.276\n```\n:::\n:::\n\n\n# Lab Session 12\n## Lab Session 12\n\n  * Compute seasonal naïve forecasts for quarterly Australian beer production.\n\n  * Test if the residuals are white noise. What do you conclude?\n\n# Forecast accuracy measures\n\n## Training and test sets\n\n\n::: {.cell hash='6-fable_cache/beamer/traintest_151c9a6a702388e1345a53e571da34fd'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/traintest-1.pdf)\n:::\n:::\n\n\n  * A model which fits the training data well will not necessarily forecast well.\n  * Forecast accuracy is based only on the test set.\n\n### Forecast errors\n\nForecast \"error\": the difference between an observed value and its forecast.\n$$\n  e_{T+h} = y_{T+h} - \\hat{y}_{T+h|T},\n$$\nwhere the training data is given by $\\{y_1,\\dots,y_T\\}$\n\n## Measures of forecast accuracy\n\\fontsize{11}{12}\\sf\n\n```r\nbeer_fit <- aus_production |>\n  filter(between(year(Quarter), 1992, 2007)) |>\n  model(\n    snaive = SNAIVE(Beer),\n    mean = MEAN(Beer)\n  )\nbeer_fit |>\n  forecast(h = \"3 years\") |>\n  autoplot(aus_production, level = NULL) +\n  labs(title =\"Forecasts for quarterly beer production\",\n       x =\"Year\", y =\"Megalitres\") +\n  guides(colour = guide_legend(title = \"Forecast\"))\n```\n\n## Measures of forecast accuracy\n\n\n::: {.cell hash='6-fable_cache/beamer/beer-fc-1_12a8dd8b44a2c93703dcc494c3d2895f'}\n::: {.cell-output-display}\n![](6-fable_files/figure-beamer/beer-fc-1-1.pdf)\n:::\n:::\n\n\n## Measures of forecast accuracy\n\n\\begin{tabular}{rl}\n$y_{T+h}=$ & $(T+h)$th observation, $h=1,\\dots,H$ \\\\\n$\\pred{y}{T+h}{T}=$ & its forecast based on data up to time $T$. \\\\\n$e_{T+h} =$  & $y_{T+h} - \\pred{y}{T+h}{T}$\n\\end{tabular}\n\n\\begin{block}{}\\vspace*{-0.7cm}\n\\begin{align*}\n\\text{MAE} &= \\text{mean}(|e_{T+h}|) \\\\[-0.2cm]\n\\text{MSE} &= \\text{mean}(e_{T+h}^2) \\qquad\n&&\\text{RMSE} &= \\sqrt{\\text{mean}(e_{T+h}^2)} \\\\[-0.1cm]\n\\text{MAPE} &= 100\\text{mean}(|e_{T+h}|/ |y_{T+h}|)\n\\end{align*}\\vspace*{-0.9cm}\n\\end{block}\n\\pause\n\n  * MAE, MSE, RMSE are all scale dependent.\n  * MAPE is scale independent but is only sensible if $y_t\\gg 0$ for all $t$, and $y$ has a natural zero.\n\n## Measures of forecast accuracy\n\\fontsize{13}{15}\\sf\n\n\\begin{block}{Mean Absolute Scaled Error}\n$$\n  \\text{MASE} = \\text{mean}(|e_{T+h}|/Q)\n$$\n\\end{block} \\pause\n\n- For non-seasonal series, scale uses naïve forecasts:\n\n\\centerline{$Q = \\frac{1}{T-1}\\displaystyle\\sum_{t=2}^T |y_{t}-y_{t-1}|$}\n\n- For seasonal series, scale uses seasonal naïve forecasts:\n\n\\centerline{$Q = \\frac{1}{T-m}\\displaystyle\\sum_{t=m+1}^T |y_{t}-y_{t-m}|$}\n\\rightline{where $m$ is the seasonal frequency}\\pause\n\nProposed by Hyndman and Koehler (IJF, 2006).\n\n## Measures of forecast accuracy\n\\fontsize{13}{15}\\sf\n\n\\begin{block}{Root Mean Squared Scaled Error}\n$$\n  \\text{RMSSE} = \\sqrt{\\text{mean}(e^2_{T+h}/Q)}\n$$\n\\end{block}\n\n- For non-seasonal series, scale uses naïve forecasts:\n\n\\centerline{$Q = \\frac{1}{T-1}\\displaystyle\\sum_{t=2}^T (y_{t}-y_{t-1})^2$}\n\n- For seasonal series, scale uses seasonal naïve forecasts:\n\n\\centerline{$Q = \\frac{1}{T-m}\\displaystyle\\sum_{t=m+1}^T (y_{t}-y_{t-m})^2$}\n\\rightline{where $m$ is the seasonal frequencyq}\n\nProposed by Hyndman and Koehler (IJF, 2006).\n\n## Measures of forecast accuracy\n\n\\fontsize{9.8}{10}\\sf\n\n\n::: {.cell hash='6-fable_cache/beamer/beer-test-accuracy_ed17d94312b332729e59baea31e150a9'}\n\n```{.r .cell-code}\nbeer_fc <- forecast(beer_fit, h = \"3 years\")\naccuracy(beer_fc, aus_production)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 10\n  .model .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE    ACF1\n  <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 mean   Test  -13.8  38.4  34.8 -3.97  8.28 2.20  1.96  -0.0691\n2 snaive Test    5.2  14.3  13.4  1.15  3.17 0.847 0.729  0.132 \n```\n:::\n:::\n\n\n# Lab Session 13\n## Lab Session 13\n\n * Create a training set for household wealth (`hh_budget`) by witholding the last four years as a test set.\n * Fit all the appropriate benchmark methods to the training set and forecast the periods covered by the test set.\n * Compute the accuracy of your forecasts. Which method does best?\n * Repeat the exercise using the Australian takeaway food turnover data (`aus_retail`) with a test set of four years.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}